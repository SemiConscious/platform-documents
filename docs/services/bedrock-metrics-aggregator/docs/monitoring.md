# Monitoring & Metrics

## Overview

The `bedrock-metrics-aggregator` service is an AWS Lambda function designed to process Bedrock invocation logs, aggregate cross-region usage metrics, and publish custom CloudWatch metrics. This document provides comprehensive guidance on the metrics published by this service, how to query them effectively, and how to set up dashboards and alarms for operational visibility.

Understanding and properly monitoring this service is critical for:
- Tracking AI inference costs across regions
- Identifying usage patterns and anomalies
- Capacity planning for Bedrock inference profiles
- Ensuring the reliability of your metrics aggregation pipeline

---

## Published Metrics Overview

The `bedrock-metrics-aggregator` publishes custom CloudWatch metrics under a dedicated namespace. These metrics provide visibility into both the operational health of the aggregator itself and the Bedrock usage patterns it tracks.

### Namespace

All metrics are published under the following CloudWatch namespace:

```
Custom/BedrockMetricsAggregator
```

### Core Metrics

| Metric Name | Unit | Description | Statistic |
|------------|------|-------------|-----------|
| `InputTokensProcessed` | Count | Total input tokens processed from Bedrock invocations | Sum, Average |
| `OutputTokensProcessed` | Count | Total output tokens generated by Bedrock models | Sum, Average |
| `TotalTokensProcessed` | Count | Combined input and output tokens | Sum, Average |
| `InvocationsProcessed` | Count | Number of Bedrock invocations processed | Sum |
| `CrossRegionInvocations` | Count | Invocations using CrossRegion inference profiles | Sum |
| `GlobalCrossRegionInvocations` | Count | Invocations using GlobalCrossRegion inference profiles | Sum |
| `RecordsProcessed` | Count | Total S3 log records processed by the Lambda | Sum |
| `ProcessingLatency` | Milliseconds | Time taken to process a batch of records | Average, P99 |
| `ProcessingErrors` | Count | Number of errors encountered during processing | Sum |
| `S3ObjectsProcessed` | Count | Number of S3 objects successfully processed | Sum |
| `SQSMessagesProcessed` | Count | Number of SQS messages processed | Sum |

### Operational Metrics

| Metric Name | Unit | Description | Statistic |
|------------|------|-------------|-----------|
| `LambdaInvocations` | Count | Number of Lambda function invocations | Sum |
| `LambdaDuration` | Milliseconds | Execution time of the Lambda function | Average, P99, Max |
| `LambdaErrors` | Count | Lambda execution errors | Sum |
| `LambdaThrottles` | Count | Lambda throttling events | Sum |
| `BatchSize` | Count | Number of records in each processed batch | Average |
| `AggregationLatency` | Milliseconds | Time spent aggregating metrics | Average |
| `CloudWatchPublishLatency` | Milliseconds | Time to publish metrics to CloudWatch | Average |

---

## Metric Dimensions

Dimensions provide additional context to your metrics, enabling more granular filtering and analysis. The `bedrock-metrics-aggregator` publishes metrics with the following dimensions:

### Primary Dimensions

| Dimension | Description | Example Values |
|-----------|-------------|----------------|
| `Region` | AWS region where the Bedrock invocation occurred | `us-east-1`, `eu-west-1`, `ap-northeast-1` |
| `InferenceProfileType` | Type of inference profile used | `CrossRegion`, `GlobalCrossRegion`, `Standard` |
| `ModelId` | Bedrock model identifier | `anthropic.claude-3-sonnet`, `amazon.titan-text-express` |
| `AccountId` | AWS account ID where invocation originated | `123456789012` |
| `FunctionName` | Name of the aggregator Lambda function | `bedrock-metrics-aggregator-prod` |

### Dimension Combinations

Metrics are published with multiple dimension combinations to support various query patterns:

```
# High-level aggregation
[InferenceProfileType]

# Regional breakdown
[Region, InferenceProfileType]

# Model-specific analysis
[Region, ModelId, InferenceProfileType]

# Account-level tracking
[AccountId, Region, ModelId]
```

### Example Dimension Structure

```json
{
  "Namespace": "Custom/BedrockMetricsAggregator",
  "MetricName": "InputTokensProcessed",
  "Dimensions": [
    {
      "Name": "Region",
      "Value": "us-east-1"
    },
    {
      "Name": "InferenceProfileType",
      "Value": "CrossRegion"
    },
    {
      "Name": "ModelId",
      "Value": "anthropic.claude-3-sonnet"
    }
  ],
  "Value": 15000,
  "Unit": "Count"
}
```

---

## Sample CloudWatch Queries

### CloudWatch Metrics Insights Queries

#### Total Token Usage by Region (Last 24 Hours)

```sql
SELECT SUM(TotalTokensProcessed)
FROM "Custom/BedrockMetricsAggregator"
GROUP BY Region
ORDER BY SUM() DESC
```

#### Cross-Region vs Global Cross-Region Usage

```sql
SELECT SUM(InvocationsProcessed)
FROM "Custom/BedrockMetricsAggregator"
WHERE InferenceProfileType IN ('CrossRegion', 'GlobalCrossRegion')
GROUP BY InferenceProfileType
```

#### Top 5 Models by Token Consumption

```sql
SELECT SUM(TotalTokensProcessed)
FROM "Custom/BedrockMetricsAggregator"
GROUP BY ModelId
ORDER BY SUM() DESC
LIMIT 5
```

#### Processing Latency Percentiles

```sql
SELECT AVG(ProcessingLatency), 
       PERCENTILE(ProcessingLatency, 95),
       PERCENTILE(ProcessingLatency, 99)
FROM "Custom/BedrockMetricsAggregator"
WHERE FunctionName = 'bedrock-metrics-aggregator-prod'
```

#### Error Rate Over Time

```sql
SELECT SUM(ProcessingErrors) / SUM(RecordsProcessed) * 100 AS ErrorRate
FROM "Custom/BedrockMetricsAggregator"
GROUP BY BIN(1h)
```

### CloudWatch Logs Insights Queries

The Lambda function also emits structured logs that can be queried for detailed analysis:

#### Find All Processing Errors

```sql
fields @timestamp, @message, errorType, errorMessage
| filter @message like /ERROR/
| sort @timestamp desc
| limit 100
```

#### Analyze Processing Duration Distribution

```sql
fields @timestamp, @duration
| stats avg(@duration) as avgDuration,
        pct(@duration, 95) as p95Duration,
        pct(@duration, 99) as p99Duration
  by bin(1h)
```

#### Track S3 Object Processing

```sql
fields @timestamp, s3Bucket, s3Key, recordCount, processingTime
| filter @message like /S3 object processed/
| stats count() as objectsProcessed,
        sum(recordCount) as totalRecords,
        avg(processingTime) as avgProcessingTime
  by bin(1h)
```

#### Identify Cross-Region Inference Patterns

```sql
fields @timestamp, sourceRegion, targetRegion, inferenceProfileType, tokenCount
| filter inferenceProfileType = 'CrossRegion'
| stats sum(tokenCount) as totalTokens by sourceRegion, targetRegion
| sort totalTokens desc
```

---

## Dashboard Setup

### Creating a Comprehensive Monitoring Dashboard

Below is a CloudFormation template snippet for creating a monitoring dashboard:

```yaml
# cloudformation/monitoring-dashboard.yaml
AWSTemplateFormatVersion: '2010-09-09'
Description: CloudWatch Dashboard for Bedrock Metrics Aggregator

Resources:
  BedrockMetricsAggregatorDashboard:
    Type: AWS::CloudWatch::Dashboard
    Properties:
      DashboardName: BedrockMetricsAggregator-Overview
      DashboardBody: !Sub |
        {
          "widgets": [
            {
              "type": "metric",
              "x": 0,
              "y": 0,
              "width": 12,
              "height": 6,
              "properties": {
                "title": "Token Usage Over Time",
                "metrics": [
                  ["Custom/BedrockMetricsAggregator", "InputTokensProcessed", {"stat": "Sum", "label": "Input Tokens"}],
                  [".", "OutputTokensProcessed", {"stat": "Sum", "label": "Output Tokens"}]
                ],
                "period": 300,
                "region": "${AWS::Region}",
                "view": "timeSeries",
                "stacked": true
              }
            },
            {
              "type": "metric",
              "x": 12,
              "y": 0,
              "width": 12,
              "height": 6,
              "properties": {
                "title": "Invocations by Inference Profile Type",
                "metrics": [
                  ["Custom/BedrockMetricsAggregator", "CrossRegionInvocations", {"stat": "Sum"}],
                  [".", "GlobalCrossRegionInvocations", {"stat": "Sum"}]
                ],
                "period": 300,
                "region": "${AWS::Region}",
                "view": "timeSeries"
              }
            },
            {
              "type": "metric",
              "x": 0,
              "y": 6,
              "width": 8,
              "height": 6,
              "properties": {
                "title": "Processing Latency",
                "metrics": [
                  ["Custom/BedrockMetricsAggregator", "ProcessingLatency", {"stat": "Average", "label": "Avg"}],
                  [".", ".", {"stat": "p99", "label": "P99"}]
                ],
                "period": 60,
                "region": "${AWS::Region}"
              }
            },
            {
              "type": "metric",
              "x": 8,
              "y": 6,
              "width": 8,
              "height": 6,
              "properties": {
                "title": "Error Count",
                "metrics": [
                  ["Custom/BedrockMetricsAggregator", "ProcessingErrors", {"stat": "Sum", "color": "#d62728"}]
                ],
                "period": 60,
                "region": "${AWS::Region}"
              }
            },
            {
              "type": "metric",
              "x": 16,
              "y": 6,
              "width": 8,
              "height": 6,
              "properties": {
                "title": "Lambda Performance",
                "metrics": [
                  ["AWS/Lambda", "Duration", "FunctionName", "bedrock-metrics-aggregator", {"stat": "Average"}],
                  [".", "Invocations", ".", ".", {"stat": "Sum", "yAxis": "right"}]
                ],
                "period": 60,
                "region": "${AWS::Region}"
              }
            },
            {
              "type": "metric",
              "x": 0,
              "y": 12,
              "width": 24,
              "height": 6,
              "properties": {
                "title": "Token Usage by Region",
                "metrics": [
                  ["Custom/BedrockMetricsAggregator", "TotalTokensProcessed", "Region", "us-east-1"],
                  [".", ".", ".", "us-west-2"],
                  [".", ".", ".", "eu-west-1"],
                  [".", ".", ".", "ap-northeast-1"]
                ],
                "period": 300,
                "region": "${AWS::Region}",
                "view": "timeSeries"
              }
            }
          ]
        }
```

### Dashboard Sections Breakdown

**1. Token Usage Overview**
- Displays input vs output token trends
- Helps identify cost drivers and usage patterns

**2. Inference Profile Analysis**
- Tracks cross-region inference usage
- Monitors global inference profile adoption

**3. Operational Health**
- Processing latency with percentile breakdowns
- Error rates and Lambda performance metrics

**4. Regional Distribution**
- Geographic breakdown of Bedrock usage
- Identifies regional hotspots

### Deploying the Dashboard via AWS CLI

```bash
# Deploy the dashboard using AWS CLI
aws cloudwatch put-dashboard \
  --dashboard-name "BedrockMetricsAggregator-Overview" \
  --dashboard-body file://dashboard-body.json

# Verify dashboard creation
aws cloudwatch get-dashboard \
  --dashboard-name "BedrockMetricsAggregator-Overview"
```

---

## Recommended Alarms

### Critical Alarms

These alarms should trigger immediate investigation and potential paging:

#### High Error Rate Alarm

```yaml
# cloudformation/alarms.yaml
HighErrorRateAlarm:
  Type: AWS::CloudWatch::Alarm
  Properties:
    AlarmName: BedrockMetricsAggregator-HighErrorRate
    AlarmDescription: Error rate exceeds 5% of processed records
    MetricName: ProcessingErrors
    Namespace: Custom/BedrockMetricsAggregator
    Statistic: Sum
    Period: 300
    EvaluationPeriods: 2
    Threshold: 50
    ComparisonOperator: GreaterThanThreshold
    TreatMissingData: notBreaching
    AlarmActions:
      - !Ref CriticalSNSTopic
```

#### Lambda Throttling Alarm

```yaml
LambdaThrottlingAlarm:
  Type: AWS::CloudWatch::Alarm
  Properties:
    AlarmName: BedrockMetricsAggregator-Throttling
    AlarmDescription: Lambda function is being throttled
    MetricName: Throttles
    Namespace: AWS/Lambda
    Dimensions:
      - Name: FunctionName
        Value: bedrock-metrics-aggregator
    Statistic: Sum
    Period: 60
    EvaluationPeriods: 1
    Threshold: 1
    ComparisonOperator: GreaterThanOrEqualToThreshold
    AlarmActions:
      - !Ref CriticalSNSTopic
```

#### Processing Latency Degradation

```yaml
HighLatencyAlarm:
  Type: AWS::CloudWatch::Alarm
  Properties:
    AlarmName: BedrockMetricsAggregator-HighLatency
    AlarmDescription: P99 processing latency exceeds 5 seconds
    MetricName: ProcessingLatency
    Namespace: Custom/BedrockMetricsAggregator
    ExtendedStatistic: p99
    Period: 300
    EvaluationPeriods: 3
    Threshold: 5000
    ComparisonOperator: GreaterThanThreshold
    AlarmActions:
      - !Ref WarningSNSTopic
```

### Warning Alarms

These alarms indicate potential issues requiring attention:

#### SQS Message Age Alarm

```yaml
SQSMessageAgeAlarm:
  Type: AWS::CloudWatch::Alarm
  Properties:
    AlarmName: BedrockMetricsAggregator-SQSBacklog
    AlarmDescription: Messages are aging in the queue indicating processing backlog
    MetricName: ApproximateAgeOfOldestMessage
    Namespace: AWS/SQS
    Dimensions:
      - Name: QueueName
        Value: bedrock-metrics-aggregator-queue
    Statistic: Maximum
    Period: 300
    EvaluationPeriods: 2
    Threshold: 3600
    ComparisonOperator: GreaterThanThreshold
    AlarmActions:
      - !Ref WarningSNSTopic
```

#### Anomaly Detection for Token Usage

```yaml
TokenUsageAnomalyAlarm:
  Type: AWS::CloudWatch::Alarm
  Properties:
    AlarmName: BedrockMetricsAggregator-TokenUsageAnomaly
    AlarmDescription: Token usage deviates significantly from normal patterns
    Metrics:
      - Id: ad1
        Expression: ANOMALY_DETECTION_BAND(m1, 2)
        Label: AnomalyDetectionBand
      - Id: m1
        MetricStat:
          Metric:
            MetricName: TotalTokensProcessed
            Namespace: Custom/BedrockMetricsAggregator
          Period: 300
          Stat: Sum
        ReturnData: true
    ThresholdMetricId: ad1
    ComparisonOperator: LessThanLowerOrGreaterThanUpperThreshold
    EvaluationPeriods: 2
    AlarmActions:
      - !Ref WarningSNSTopic
```

### Alarm Summary Table

| Alarm Name | Severity | Threshold | Action |
|-----------|----------|-----------|--------|
| High Error Rate | Critical | >50 errors/5min | Page on-call |
| Lambda Throttling | Critical | â‰¥1 throttle | Page on-call |
| High Latency (P99) | Warning | >5s for 15min | Notify team |
| SQS Backlog | Warning | >1hr message age | Notify team |
| Token Usage Anomaly | Warning | 2 std deviations | Notify team |
| Lambda Errors | Warning | >10 errors/5min | Notify team |
| No Data Received | Warning | 0 records/30min | Investigate |

---

## Logging Configuration

### Lambda Logging Setup

The `bedrock-metrics-aggregator` uses structured JSON logging for optimal CloudWatch Logs Insights querying:

```typescript
// src/utils/logger.ts
import { Logger } from '@aws-lambda-powertools/logger';

export const logger = new Logger({
  serviceName: 'bedrock-metrics-aggregator',
  logLevel: process.env.LOG_LEVEL || 'INFO',
  persistentLogAttributes: {
    environment: process.env.ENVIRONMENT,
    version: process.env.VERSION
  }
});
```

```python
# src/utils/logger.py
import json
import logging
import os
from datetime import datetime

class StructuredLogger:
    def __init__(self, service_name: str):
        self.logger = logging.getLogger(service_name)
        self.logger.setLevel(os.environ.get('LOG_LEVEL', 'INFO'))
        self.service_name = service_name
        self.environment = os.environ.get('ENVIRONMENT', 'dev')
    
    def info(self, message: str, **kwargs):
        self._log('INFO', message, **kwargs)
    
    def error(self, message: str, **kwargs):
        self._log('ERROR', message, **kwargs)
    
    def _log(self, level: str, message: str, **kwargs):
        log_entry = {
            'timestamp': datetime.utcnow().isoformat(),
            'level': level,
            'service': self.service_name,
            'environment': self.environment,
            'message': message,
            **kwargs
        }
        print(json.dumps(log_entry))
```

### Log Levels

| Level | Use Case | Example |
|-------|----------|---------|
| `DEBUG` | Detailed diagnostic information | Record-level processing details |
| `INFO` | General operational events | Batch processing started/completed |
| `WARN` | Potentially problematic situations | Retry attempts, degraded performance |
| `ERROR` | Error events that might still allow operation | Failed record processing |

### Log Retention Configuration

```yaml
# cloudformation/log-retention.yaml
LogGroup:
  Type: AWS::Logs::LogGroup
  Properties:
    LogGroupName: /aws/lambda/bedrock-metrics-aggregator
    RetentionInDays: 30
    Tags:
      - Key: Environment
        Value: !Ref Environment
      - Key: Service
        Value: bedrock-metrics-aggregator

# Metric filters for log-based metrics
ProcessingErrorMetricFilter:
  Type: AWS::Logs::MetricFilter
  Properties:
    LogGroupName: !Ref LogGroup
    FilterPattern: '{ $.level = "ERROR" }'
    MetricTransformations:
      - MetricName: LoggedErrors
        MetricNamespace: Custom/BedrockMetricsAggregator
        MetricValue: 1
        DefaultValue: 0
```

### Structured Log Examples

**Successful Processing:**
```json
{
  "timestamp": "2024-01-15T10:30:00.000Z",
  "level": "INFO",
  "service": "bedrock-metrics-aggregator",
  "message": "Batch processing completed",
  "batchId": "abc-123",
  "recordsProcessed": 150,
  "inputTokens": 45000,
  "outputTokens": 12000,
  "processingTimeMs": 1250,
  "s3Bucket": "bedrock-logs-bucket",
  "s3Key": "logs/2024/01/15/invocations.json"
}
```

**Error Log:**
```json
{
  "timestamp": "2024-01-15T10:30:05.000Z",
  "level": "ERROR",
  "service": "bedrock-metrics-aggregator",
  "message": "Failed to process S3 object",
  "errorType": "S3AccessDenied",
  "errorMessage": "Access Denied",
  "s3Bucket": "bedrock-logs-bucket",
  "s3Key": "logs/2024/01/15/corrupted.json",
  "requestId": "req-456",
  "retryCount": 3
}
```

### Log Subscription for Extended Analysis

```yaml
LogSubscription:
  Type: AWS::Logs::SubscriptionFilter
  Properties:
    LogGroupName: !Ref LogGroup
    FilterPattern: '{ $.level = "ERROR" || $.level = "WARN" }'
    DestinationArn: !GetAtt LogAnalyticsKinesisStream.Arn
    RoleArn: !GetAtt LogSubscriptionRole.Arn
```

---

## Best Practices

### Metric Publishing

1. **Batch metric publishing** to reduce API calls and costs
2. **Use appropriate metric resolution** (1-minute for critical metrics, 5-minute for cost metrics)
3. **Include all relevant dimensions** for flexible querying
4. **Set meaningful units** for each metric

### Dashboard Design

1. **Organize by persona** - separate operational and business dashboards
2. **Use appropriate time ranges** - default to relevant windows
3. **Include annotation widgets** for context during incidents
4. **Group related metrics** visually

### Alarm Configuration

1. **Set appropriate evaluation periods** to avoid alert fatigue
2. **Use composite alarms** for complex conditions
3. **Document runbooks** for each alarm
4. **Test alarms regularly** in non-production environments

---

## Troubleshooting

### Common Issues

| Symptom | Possible Cause | Resolution |
|---------|---------------|------------|
| Missing metrics | IAM permissions | Verify CloudWatch:PutMetricData permission |
| Delayed metrics | High SQS backlog | Scale Lambda concurrency |
| Incomplete data | S3 access issues | Check S3 bucket policy |
| Alarm not triggering | Incorrect dimensions | Verify dimension names match |

### Debug Queries

```sql
-- Find processing gaps
fields @timestamp
| filter @message like /Batch processing completed/
| stats count() by bin(5m)
| sort @timestamp asc
```

This documentation provides a comprehensive foundation for monitoring the `bedrock-metrics-aggregator` service. Regular review and updates to dashboards and alarms are recommended as usage patterns evolve.