"""
AI-Powered Template Generator.

Uses Claude to analyze a repository and generate an optimal
documentation structure tailored to its specific characteristics.

Instead of hardcoded templates per repo type, this dynamically
creates documentation plans based on what Claude sees in the code.
"""

import json
import logging
import re
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Optional

logger = logging.getLogger("doc-agent.documentation.ai_template_generator")


@dataclass
class DocumentTemplate:
    """
    A template for a single document to be generated.
    """
    path: str                           # Relative path (e.g., "api/endpoints.md")
    title: str                          # Document title
    description: str                    # What this document should contain
    sections: list[str] = field(default_factory=list)  # Suggested sections
    priority: int = 1                   # Generation order (1=highest)
    required: bool = True               # Whether this doc is essential
    links_to: list[str] = field(default_factory=list)  # Child docs to link to
    
    def to_dict(self) -> dict:
        return {
            "path": self.path,
            "title": self.title,
            "description": self.description,
            "sections": self.sections,
            "priority": self.priority,
            "required": self.required,
            "links_to": self.links_to,
        }


@dataclass
class DocumentationPlan:
    """
    Complete documentation plan for a repository.
    
    Generated by AI based on repository analysis.
    """
    service_name: str
    repo_type: str                      # API, Lambda, Terraform, Library, etc.
    description: str                    # Overall service description
    documents: list[DocumentTemplate] = field(default_factory=list)
    key_features: list[str] = field(default_factory=list)  # Main capabilities
    target_audience: str = "developers"  # Who will read these docs
    
    def to_dict(self) -> dict:
        return {
            "service_name": self.service_name,
            "repo_type": self.repo_type,
            "description": self.description,
            "documents": [d.to_dict() for d in self.documents],
            "key_features": self.key_features,
            "target_audience": self.target_audience,
        }
    
    def get_documents_by_priority(self) -> list[DocumentTemplate]:
        """Get documents sorted by priority (lowest number = highest priority)."""
        return sorted(self.documents, key=lambda d: d.priority)


class AITemplateGenerator:
    """
    Generates custom documentation templates using AI.
    
    Analyzes repository structure and content to determine:
    - What type of project this is
    - What documents would be most valuable
    - What sections each document should have
    - The optimal organization structure
    """
    
    def __init__(
        self,
        llm_client: Any,
        model_selector: Any = None,
        token_tracker: Any = None,
    ):
        """
        Initialize the template generator.
        
        Args:
            llm_client: Anthropic client (Bedrock or direct)
            model_selector: Model selector for operation-specific models
            token_tracker: Token usage tracker
        """
        self.llm_client = llm_client
        self.model_selector = model_selector
        self.token_tracker = token_tracker
    
    def _get_model(self, operation_type: str = "templates") -> str:
        """Get the appropriate model for template generation."""
        if self.model_selector:
            from ..llm import Operation
            try:
                op = Operation(operation_type)
                return self.model_selector.get_model(op)
            except (ValueError, AttributeError):
                pass
        
        # Fallback - use Haiku for template generation (cost-efficient)
        return "us.anthropic.claude-3-5-haiku-20241022-v1:0"
    
    async def _call_llm(
        self,
        prompt: str,
        system_prompt: str,
        max_tokens: int = 4096,
        operation: str = "templates",
    ) -> str:
        """Call the LLM and track tokens."""
        if not self.llm_client:
            return ""
        
        model = self._get_model(operation)
        
        try:
            response = await self.llm_client.messages.create(
                model=model,
                max_tokens=max_tokens,
                system=system_prompt,
                messages=[{"role": "user", "content": prompt}],
            )
            
            if self.token_tracker and hasattr(response, "usage"):
                self.token_tracker.record(response, f"template_gen_{operation}")
            
            return response.content[0].text if response.content else ""
            
        except Exception as e:
            logger.error(f"Template generation LLM call failed: {e}")
            return ""
    
    async def generate_plan(
        self,
        repo_path: Path,
        service_name: str,
        existing_analysis: Optional[Any] = None,
    ) -> DocumentationPlan:
        """
        Generate a documentation plan for a repository.
        
        Args:
            repo_path: Path to the repository
            service_name: Name of the service
            existing_analysis: Optional pre-existing analysis result
            
        Returns:
            DocumentationPlan with custom structure for this repo
        """
        logger.info(f"Generating documentation plan for {service_name}")
        
        # Gather repository context
        context = await self._gather_context(repo_path, existing_analysis)
        
        # Generate the plan using AI
        plan = await self._generate_plan_with_ai(service_name, context)
        
        if not plan:
            # Fallback to default plan
            logger.warning(f"AI plan generation failed, using default for {service_name}")
            plan = self._get_default_plan(service_name, context)
        
        logger.info(f"Generated plan with {len(plan.documents)} documents for {service_name}")
        return plan
    
    async def _gather_context(
        self,
        repo_path: Path,
        existing_analysis: Optional[Any],
    ) -> dict:
        """Gather context about the repository for template generation."""
        context = {
            "files": [],
            "readme": "",
            "package_info": {},
            "analysis_summary": {},
        }
        
        # Get file list (limited)
        try:
            all_files = []
            for ext in [".php", ".py", ".ts", ".js", ".go", ".java", ".tf", ".yaml", ".yml"]:
                all_files.extend(repo_path.rglob(f"*{ext}"))
            
            # Filter out common excludes
            files = [
                str(f.relative_to(repo_path)) 
                for f in all_files[:100]
                if not any(x in str(f) for x in ["node_modules", "vendor", ".git", "test", "spec", "__pycache__"])
            ]
            context["files"] = files[:50]  # Limit for prompt size
        except Exception as e:
            logger.warning(f"Failed to list files: {e}")
        
        # Read README if exists
        for readme_name in ["README.md", "readme.md", "README.rst", "README"]:
            readme_path = repo_path / readme_name
            if readme_path.exists():
                try:
                    content = readme_path.read_text(errors='ignore')
                    context["readme"] = content[:3000]  # Limit size
                except Exception:
                    pass
                break
        
        # Check for package files
        package_files = {
            "package.json": "npm",
            "composer.json": "composer",
            "requirements.txt": "pip",
            "go.mod": "go",
            "Cargo.toml": "cargo",
            "pom.xml": "maven",
            "serverless.yml": "serverless",
            "template.yaml": "sam",
        }
        
        for filename, pkg_type in package_files.items():
            pkg_path = repo_path / filename
            if pkg_path.exists():
                context["package_info"]["type"] = pkg_type
                try:
                    if filename.endswith(".json"):
                        content = json.loads(pkg_path.read_text())
                        context["package_info"]["name"] = content.get("name", "")
                        context["package_info"]["description"] = content.get("description", "")
                except Exception:
                    pass
                break
        
        # Include analysis summary if available
        if existing_analysis:
            endpoints = getattr(existing_analysis, 'endpoints', [])
            models = getattr(existing_analysis, 'models', [])
            
            # Provide sample endpoints/models so AI can see patterns and decide how to group
            endpoint_samples = [
                f"{getattr(ep, 'method', 'GET')} {getattr(ep, 'path', '')}"
                for ep in endpoints[:50]
            ]
            model_samples = [getattr(m, 'name', '') for m in models[:30]]
            
            context["analysis_summary"] = {
                "endpoints_count": len(endpoints),
                "models_count": len(models),
                "config_count": len(getattr(existing_analysis, 'config', [])),
                "has_database": any(
                    getattr(se, 'category', None) and 'DATABASE' in str(getattr(se, 'category', ''))
                    for se in getattr(existing_analysis, 'side_effects', [])
                ),
                "endpoint_samples": endpoint_samples,
                "model_samples": model_samples,
            }
        
        return context
    
    async def _generate_plan_with_ai(
        self,
        service_name: str,
        context: dict,
    ) -> Optional[DocumentationPlan]:
        """Use AI to generate the documentation plan."""
        
        # Build prompt with context
        files_list = "\n".join(context.get("files", [])[:30])
        readme_excerpt = context.get("readme", "")[:1500]
        pkg_info = context.get("package_info", {})
        analysis = context.get("analysis_summary", {})
        
        # Include endpoint/model samples so AI can see patterns
        endpoint_samples = analysis.get("endpoint_samples", [])
        model_samples = analysis.get("model_samples", [])
        endpoint_sample_text = "\n".join(endpoint_samples[:30]) if endpoint_samples else "None"
        model_sample_text = ", ".join(model_samples[:20]) if model_samples else "None"
        
        prompt = f"""Analyze this repository and create an optimal documentation structure.

SERVICE NAME: {service_name}

PACKAGE INFO:
- Type: {pkg_info.get('type', 'unknown')}
- Name: {pkg_info.get('name', 'unknown')}
- Description: {pkg_info.get('description', 'No description')}

FILE STRUCTURE (sample):
{files_list}

README EXCERPT:
{readme_excerpt[:1000] if readme_excerpt else 'No README found'}

ANALYSIS SUMMARY:
- Endpoints found: {analysis.get('endpoints_count', 'unknown')}
- Data models found: {analysis.get('models_count', 'unknown')}
- Config variables: {analysis.get('config_count', 'unknown')}
- Has database operations: {analysis.get('has_database', 'unknown')}

SAMPLE ENDPOINTS:
{endpoint_sample_text}

SAMPLE MODELS:
{model_sample_text}

Based on this information, generate a documentation plan. Consider:
1. What type of project is this? (API service, Lambda function, library, Terraform module, etc.)
2. Who is the target audience? (developers integrating with it, ops deploying it, etc.)
3. What documents would be most valuable?
4. What should each document contain?

IMPORTANT - DOCUMENT SIZE GUIDELINES:
- Each document should be readable in one sitting (target ~50-100 items per document max)
- If there are many endpoints (>50), split API docs by functional area (look at the path patterns)
- If there are many models (>30), split model docs by domain/category
- Create an index/overview document that links to the sub-documents
- Use your judgment to group logically based on the patterns you see in the endpoints/models

DOCUMENT LINKING:
- Parent documents (like api/README.md) should list and link to child documents
- Include a "Related Documents" section where appropriate
- The README.md should link to all major documentation sections

OUTPUT FORMAT (JSON):
{{
  "repo_type": "api_service|lambda|library|terraform|frontend|etc",
  "description": "Brief description of what this service does",
  "key_features": ["feature1", "feature2"],
  "target_audience": "developers|operators|integrators",
  "documents": [
    {{
      "path": "README.md",
      "title": "Overview",
      "description": "What this document should explain",
      "sections": ["Introduction", "Quick Start", "Architecture", "Documentation Index"],
      "priority": 1,
      "required": true,
      "links_to": ["api/README.md", "models/README.md"]
    }},
    {{
      "path": "api/README.md",
      "title": "API Overview",
      "description": "API introduction with links to detailed endpoint docs",
      "sections": ["Authentication", "API Index", "Common Patterns"],
      "priority": 2,
      "required": true,
      "links_to": ["api/authentication.md", "api/users.md"]
    }},
    {{
      "path": "api/authentication.md",
      "title": "Authentication Endpoints",
      "description": "Auth and token endpoints",
      "sections": ["Endpoints", "Examples"],
      "priority": 3,
      "required": true
    }}
  ]
}}

Important:
- Create documents based on logical groupings you see in the endpoints/models
- Prioritize documents (1=most important)
- Include practical sections that developers need
- Use subdirectories for organization (api/, models/, etc.)
- Only output valid JSON"""

        system_prompt = """You are a technical documentation architect.
Your job is to analyze codebases and design optimal documentation structures.
Consider the audience, the project type, and what information would be most valuable.
Always output valid JSON."""

        response = await self._call_llm(
            prompt=prompt,
            system_prompt=system_prompt,
            max_tokens=16000,  # High limit for complex multi-document plans
            operation="templates",
        )
        
        return self._parse_plan_response(response, service_name)
    
    def _repair_truncated_json(self, json_str: str) -> str:
        """
        Attempt to repair truncated JSON by closing unclosed brackets/braces.
        """
        # Count unclosed brackets
        open_braces = json_str.count('{') - json_str.count('}')
        open_brackets = json_str.count('[') - json_str.count(']')
        
        # Check for unterminated strings
        quote_count = len(re.findall(r'(?<!\\)"', json_str))
        if quote_count % 2 != 0:
            json_str = json_str.rstrip()
            if not json_str.endswith('"'):
                json_str += '"'
        
        # Remove trailing incomplete elements
        json_str = re.sub(r',\s*$', '', json_str)
        json_str = re.sub(r',\s*"[^"]*$', '', json_str)  # Incomplete key
        json_str = re.sub(r':\s*$', ': null', json_str)  # Incomplete value
        
        # Close unclosed braces/brackets
        json_str += '}' * max(0, open_braces)
        json_str += ']' * max(0, open_brackets)
        
        return json_str
    
    def _parse_plan_response(
        self,
        response: str,
        service_name: str,
    ) -> Optional[DocumentationPlan]:
        """Parse the AI response into a DocumentationPlan."""
        try:
            # Extract JSON from response
            json_str = response.strip()
            if "```json" in json_str:
                json_str = json_str.split("```json")[1].split("```")[0]
            elif "```" in json_str:
                parts = json_str.split("```")
                if len(parts) >= 2:
                    json_str = parts[1]
            
            json_str = json_str.strip()
            
            # Try parsing as-is first
            try:
                data = json.loads(json_str)
            except json.JSONDecodeError:
                # Try repairing truncated JSON
                repaired = self._repair_truncated_json(json_str)
                data = json.loads(repaired)
                logger.debug("Successfully parsed repaired template JSON")
            
            # Build document templates
            documents = []
            for doc_data in data.get("documents", []):
                if isinstance(doc_data, dict) and doc_data.get("path"):
                    documents.append(DocumentTemplate(
                        path=doc_data.get("path", ""),
                        title=doc_data.get("title", ""),
                        description=doc_data.get("description", ""),
                        sections=doc_data.get("sections", []),
                        priority=doc_data.get("priority", 5),
                        required=doc_data.get("required", True),
                        links_to=doc_data.get("links_to", []),
                    ))
            
            if not documents:
                return None
            
            return DocumentationPlan(
                service_name=service_name,
                repo_type=data.get("repo_type", "unknown"),
                description=data.get("description", ""),
                documents=documents,
                key_features=data.get("key_features", []),
                target_audience=data.get("target_audience", "developers"),
            )
            
        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse AI template response: {e}")
            return None
        except Exception as e:
            logger.warning(f"Error processing AI template response: {e}")
            return None
    
    def _get_default_plan(
        self,
        service_name: str,
        context: dict,
    ) -> DocumentationPlan:
        """Get a sensible default plan when AI fails."""
        
        # Detect type from context
        pkg_type = context.get("package_info", {}).get("type", "")
        files = context.get("files", [])
        
        if "serverless" in pkg_type or "sam" in pkg_type or any("lambda" in f.lower() for f in files):
            repo_type = "lambda"
        elif any("terraform" in f.lower() or f.endswith(".tf") for f in files):
            repo_type = "terraform"
        elif any("controller" in f.lower() or "route" in f.lower() for f in files):
            repo_type = "api_service"
        else:
            repo_type = "library"
        
        # Default documents based on type
        documents = [
            DocumentTemplate(
                path="README.md",
                title="Overview",
                description="Service overview and quick start guide",
                sections=["Introduction", "Getting Started", "Architecture"],
                priority=1,
                required=True,
            ),
        ]
        
        if repo_type == "api_service":
            documents.extend([
                DocumentTemplate(
                    path="api/endpoints.md",
                    title="API Reference",
                    description="Complete endpoint documentation",
                    sections=["Authentication", "Endpoints", "Error Codes"],
                    priority=2,
                    required=True,
                ),
                DocumentTemplate(
                    path="data/models.md",
                    title="Data Models",
                    description="Data structures and schemas",
                    sections=["Core Models", "Request/Response Types"],
                    priority=3,
                    required=True,
                ),
            ])
        elif repo_type == "lambda":
            documents.extend([
                DocumentTemplate(
                    path="functions.md",
                    title="Functions",
                    description="Lambda function documentation",
                    sections=["Functions Overview", "Event Handlers", "Environment Variables"],
                    priority=2,
                    required=True,
                ),
            ])
        elif repo_type == "terraform":
            documents.extend([
                DocumentTemplate(
                    path="resources.md",
                    title="Resources",
                    description="Terraform resources documentation",
                    sections=["Resources", "Variables", "Outputs"],
                    priority=2,
                    required=True,
                ),
            ])
        
        # Always include configuration if we found config
        analysis = context.get("analysis_summary", {})
        if analysis.get("config_count", 0) > 0:
            documents.append(DocumentTemplate(
                path="configuration.md",
                title="Configuration",
                description="Environment variables and configuration options",
                sections=["Environment Variables", "Configuration Files"],
                priority=4,
                required=False,
            ))
        
        return DocumentationPlan(
            service_name=service_name,
            repo_type=repo_type,
            description=f"Documentation for {service_name}",
            documents=documents,
            key_features=[],
            target_audience="developers",
        )
